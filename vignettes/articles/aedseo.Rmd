---
title: "Automated and Early Detection of Seasonal Epidemic Onset"
bibliography: "references.bib"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(aedseo)
library(ISOweek)
library(ggplot2)
library(dplyr)
library(tidyr)
library(tibble)
library(tsibble)
library(kableExtra)
```


## Introduction


Understanding the seasonality of respiratory virus infections is crucial for countries to make informed recommendations concerning the timing of monoclonal antibody provision, particularly for the treatment and prophylaxis of children in their first year(s) of life, primarily premature infants [@Terletskaia_2005, @Teirlinck_2023]. Moreover, the timely detection of epidemic onset has the potential to guide empirical antiviral therapy for hospitalized patients with suspected influenza [@McGeer_2009]. This, in turn, contributes to the reduction of the health an economic burden caused by respiratory virus infections. Achieving accurate identification of the beginning of seasonal respiratory epidemics necessitates regular and prompt data collection, coupled with a standardized procedure for continuous data analysis.

A wide range of statistical methods are at out disposal for defining influenza epidemics. Over the last two decades, techniques such as Serfling-based models and dynamic linear models, which rely on recent data [@Serfling_1963, @Stroup_1989, @West_1997, @Pelat_2007], have been extensively employed for this purpose.

This package revolves around the timely detection of the onset of seasonal respiratory epidemics.

## Methodology




## Simulations

To assess the effectiveness of the proposed algorithm, a simulation study is conducted. The simulated data is generated using a negative binomial model with a mean parameter $\mu$ and a variance parameter $\phi\mu$. In this context, $\phi$ denotes a dispersion parameter, which is assumed to be greater than or equal to 1. The mean, denoted as $\mu(t)$, is defined by a linear predictor that incorporates both a trend component and a seasonality components represented by Fourier terms. The equation for $\mu(t)$ is as follows:

\begin{equation}
  \mu(t) = \exp\Biggl( \theta + \beta t + \sum_{j=1}^m \biggl( \gamma_{\sin} \sin\Bigl( \frac{2 \pi t}{52}\Bigl) + \gamma_{\cos} \cos \Bigl( \frac{2 \pi t}{52} \Bigl) \biggl) \Biggl)
\end{equation}

To accommodate a variety of scenarios encountered in practical applications, the simulations is generated using different combinations of parameters. These parameters include baseline frequencies of reports denoted as $\theta$, trends represented by $\beta$, seasonal patterns characterized by $\gamma_{\sin}$ and $\gamma_{\cos}$, as well as dispersions indicated by $\phi$. A list of the specific parameter combinations are provided in Table XX.


```{r parameter_combinations}

parameter_combinations <- as_tibble(expand_grid(theta = c(3,4,5,6,7), beta = c(0.001), gamma_sin = c(1,2), gamma_cos = c(1,2), phi = c(1,2)))  

parameter_combinations %>%
  mutate(Scenario = row_number()) %>%
  select(Scenario, theta:phi) %>%
  rename(`$\\theta$` = theta, `$\\beta$` = beta, `$\\gamma_{\\sin}$` = gamma_sin, `$\\gamma_{\\cos}$` = gamma_cos, `$\\phi$` = phi) %>%
  kbl(booktabs = TRUE, escape = FALSE, align = "l", caption = "Parameters and criteria to generate the 40 scenarios.",
      linesep = c(rep("",7),"\\addlinespace")) %>%
  kable_paper(latex_options = c("HOLD_position"))

```


```{r}

mu_t <- function(t, theta = 1, exp_beta = 1.001, gamma_sin = 1, gamma_cos = 1, trend = 1, j = 1, ...){
  # Start construction of linear predictor
  linear_predictor <- theta
  # ... add a trend if the scenario request it
  if(trend == 1){
    linear_predictor <- linear_predictor + log(exp_beta)*t
  }
  # ... add a seasonal component
  linear_predictor <- linear_predictor + gamma_sin * sin( 2*pi*t*j / 52 )+ gamma_cos * cos( 2*pi*t*j / 52 ) 

  return( exp(linear_predictor) )
}

simulate_from_nbinom <- function(...){
  # Set some default values for the simulation
  default_pars = list(
    "t" = 1,
    "theta" = 1,
    "exp_beta" = 1.001,
    "gamma_sin" = 1,
    "gamma_cos" = 1,
    "trend" = 1,
    "j" = 1,
    "phi" = 1,
    "seed" = 42
    )
  
  # Match call
  mc <- as.list(match.call())[-1]
  # ... and change parameters relative to the call
  mc <- append(mc, default_pars[!names(default_pars) %in% names(mc)])[names(default_pars)]
  
  # Set the seed
  set.seed(mc$seed)
  
  # Calculate the number of time points
  n <- length(eval(mc$t))
  # Calculate mu_t
  mu_t_scenario <- do.call(what = "mu_t", args = mc)
  # ... and compute the variance of the negative binomial distribution
  variance = mu_t_scenario * mc$phi
  # ... and infer the size in the negative binomial distribution
  size = (mu_t_scenario + mu_t_scenario^2) / variance
  # Plugin and simulate the data
  simulation <- rnbinom(n = n, mu = mu_t_scenario, size = size)
  
  return(list("mu_t" = mu_t_scenario, "simulation" = simulation, "pars" = mc))
  
}

```


```{r}

# Define the number of years and the number of months within a year
years <- 3
weeks <- 52
# ... calculate the total number of observations
n <- years*weeks
# ... and a vector containing the overall time passed
timeOverall <- 1:n
# Create arbitrary dates
dates <- as.POSIXct(x = timeOverall*86400*7,
           origin = "2010-01-01",
           tz = "UTC",
           format = "%F")

# Simulate the data
simulation <- simulate_from_nbinom(t = timeOverall)

# Collect the data in a 'tibble'
sim_data <- tibble(Date = dates, mu_t = simulation$mu_t, y = simulation$simulation)

# Have a glance at the time varying mean
sim_data %>%
  pivot_longer(cols = mu_t:y, names_to = "type", values_to = "value") %>%
  ggplot(mapping = aes(x = Date, y = value)) +
  geom_line() +
  geom_point() +
  facet_wrap(facets = vars(type), ncol = 1)

sim_data %>%
  ggplot(mapping = aes(x = Date)) +
  geom_line(mapping = aes(y = mu_t)) +
  geom_point(mapping = aes(y = y)) 

# Construct a 'tsibble' object with the time series data
tsd_data <- tsd(
  observed = simulation$simulation,
  time = dates,
  time_interval = "week"
  )

# Apply the 'aedseo' algorithm
aedseo_results <- aedseo(tsd = tsd_data, k = 5, level = 0.95, family = "quasipoisson")

# Visualize the growth rate
aedseo_results %>%
  ggplot(mapping = aes(x = reference_time, y = growth_rate)) +
  geom_line() +
  geom_ribbon(mapping = aes(ymin = lower_growth_rate, ymax = upper_growth_rate), alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_x_yearweek()

aedseo_results %>%
  ggplot(mapping = aes(x = reference_time)) +
  geom_point(mapping = aes(y = growth_rate, alpha = growth_warning)) +
  geom_errorbar(mapping = aes(ymin = lower_growth_rate, ymax = upper_growth_rate, alpha = growth_warning)) +
  geom_hline(yintercept = 0, linetype = "dashed")

```



```{r, eval=FALSE, include=FALSE}
# Define a vector containing the weeks within a year, replicated for each year
timeInYear <- rep(x = 1:weeks, times = years)

# Define the mean number of cases
theta <- 5
# ... and a trend
exp_beta <- 1.001
# ... and seasonal parameters
gamma_sin <- gamma_cos <- 1

# Calculate the time varying mean
mu_t <- exp(theta + timeOverall*log(exp_beta) + gamma_sin * sin(2*pi*timeInYear/52) + gamma_cos * cos(2*pi*timeInYear/52))

# Draw a realization from the negative binomial distribution
sim_nbinom <- rnbinom(n = n, mu = mu_t, size = 10)
```

